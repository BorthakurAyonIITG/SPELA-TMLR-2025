{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './../../../Models')\n",
    "from sphere_points import generate_points\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import SGD\n",
    "from torch.nn.functional import normalize, one_hot\n",
    "# import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    losses = np.array(losses)\n",
    "    n_dims, epochs = losses.shape\n",
    "    plt.figure(figsize = (12, 5))\n",
    "    for l in range(n_dims):\n",
    "        plt.subplot(1, n_dims, l + 1)\n",
    "        plt.plot(1 + np.arange(epochs), losses[l])\n",
    "        plt.title(f\"Layer {l + 1} Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loss = nn.CrossEntropyLoss()\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_head_train(inp_embedding, classifier_weights, labels):\n",
    "    # model_loss = nn.CrossEntropyLoss()\n",
    "    inp_embedding = normalize(inp_embedding, p=2, dim=-1)\n",
    "    classifier_output = torch.mm(inp_embedding, classifier_weights)\n",
    "    # classifier_output = 1 - (torch.acos(classifier_output)/np.pi)\n",
    "    classifier_output = classifier_output * one_hot(labels, num_classes = num_classes).type(torch.float32)\n",
    "    # classifier_output = torch.softmax(classifier_output, dim=-1)\n",
    "    # loss = model_loss(classifier_output, one_hot(labels, num_classes = num_classes).type(torch.float32))\n",
    "    theta = 1\n",
    "    loss = torch.mean(torch.log(2 - (theta * torch.sum(classifier_output,1))))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_head(inp_embedding, classifier_weights, labels):\n",
    "    inp_embedding = normalize(inp_embedding, p=2, dim=-1)\n",
    "    classifier_output = torch.mm(inp_embedding, classifier_weights)\n",
    "    # classifier_output = 1 - (torch.acos(classifier_output)/np.pi)\n",
    "    # classifier_output = torch.softmax(classifier_output, dim=-1)\n",
    "    # loss = model_loss(classifier_output, one_hot(labels, num_classes = num_classes).type(torch.float32))\n",
    "    return torch.argmax(classifier_output, dim=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = None\n",
    "# num_classes = 10\n",
    "\n",
    "# Data dimension\n",
    "# (num_data, num_features) => no dimension for batch size please\n",
    "class Layer(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias, device, lr, apply_dropout=False):\n",
    "        super().__init__(in_features, out_features, bias, device)\n",
    "        self.out_features = out_features\n",
    "        self.bias_flag = bias\n",
    "        self.lr = lr\n",
    "        self.num_classes = num_classes\n",
    "        self.dimension = out_features\n",
    "        # self.activation = DyT(1)\n",
    "        # self.activation = nn.LeakyReLU(negative_slope=0.001)\n",
    "        # self.leaky_relu = nn.LeakyReLU(negative_slope=0.001)\n",
    "        # self.activation = nn.GELU()\n",
    "        # self.opt = Adam(self.parameters(), lr = self.lr)\n",
    "        # self.opt = SGD(self.parameters(), lr=self.lr, momentum=0.9)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.opt, \n",
    "        #                                                       milestones=[60], gamma=0.1)\n",
    "        # nn.init.kaiming_normal_(self.weight, mode='fan_in')\n",
    "        \n",
    "        fc1_limit = np.sqrt(6.0 / in_features)\n",
    "        torch.nn.init.uniform_(self.weight, a=-fc1_limit, b=fc1_limit)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.apply_dropout = apply_dropout\n",
    "        global initial\n",
    "\n",
    "        '''\n",
    "        self.directions = generate_points(self.num_classes, self.dimension, steps = 10000)\n",
    "        '''\n",
    "        self.directions = np.random.randn(self.num_classes, self.dimension)\n",
    "        initial = np.array(self.directions)\n",
    "        self.directions = [torch.tensor(t, dtype = torch.float32).to(device) for t in self.directions]\n",
    "        self.direction_weights = torch.zeros((len(self.directions[0]), len(self.directions)), device=device, \n",
    "                                             requires_grad=False)\n",
    "        for i in range(len(self.directions)):\n",
    "            self.direction_weights[:, i] = normalize(self.directions[i], p = 2, dim=-1)\n",
    "\n",
    "    def train(self, x, labels):\n",
    "        if self.apply_dropout:\n",
    "            x = self.dropout(x)\n",
    "        # activation = nn.ELU()\n",
    "        activation = nn.LeakyReLU(negative_slope=0.001)\n",
    "        # activation = nn.Tanh()\n",
    "        # activation = self.activation\n",
    "        # opt = SGD(self.parameters(), lr=self.lr, momentum=0.9)\n",
    "        opt = SGD(self.parameters(), lr=self.lr)\n",
    "        # activation = nn.GELU()\n",
    "        # activation = nn.ReLU()\n",
    "        # opt = Adam(self.parameters(), lr=self.lr)\n",
    "        # print(f\"gpu used {torch.cuda.max_memory_allocated(device=None)} memory\")\n",
    "        if self.bias_flag:\n",
    "            y = activation(torch.mm(x, self.weight.T) + self.bias.unsqueeze(0))\n",
    "        else:\n",
    "            y = activation(torch.mm(x, self.weight.T))\n",
    "        # if self.apply_dropout:\n",
    "        #     x = self.dropout(x)\n",
    "        # y = self.forward(x) # shape: (num_data, out_features)\n",
    "        '''\n",
    "        y = normalize(y, p = 2, dim = 1)\n",
    "        '''\n",
    "        # import pdb;pdb.set_trace()\n",
    "        loss = classifier_head_train(y, self.direction_weights, labels)\n",
    "        \n",
    "        '''\n",
    "        directions = torch.zeros_like(y)\n",
    "        for i in range(y.shape[0]):\n",
    "            directions[i, :] = self.directions[label[i]]\n",
    "        \n",
    "        loss = loss_layer(y, directions)\n",
    "        '''\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward(retain_graph = False)\n",
    "        opt.step()\n",
    "        # self.scheduler.step()\n",
    "        \n",
    "        # normalize the directions\n",
    "        # self.directions.data = normalize(self.directions.data, p = 2, dim = 1)\n",
    "\n",
    "        return loss.detach().item(), y\n",
    "    \n",
    "    def test(self, x, labels):\n",
    "        with torch.no_grad():\n",
    "            # activation = nn.ELU()\n",
    "            # y = self.forward(x)\n",
    "            activation = nn.LeakyReLU(negative_slope=0.001)\n",
    "            # activation = nn.ReLU()\n",
    "            # activation = nn.GELU()\n",
    "            # activation = nn.Tanh()\n",
    "            # activation = self.activation\n",
    "            if self.bias_flag:\n",
    "                y = activation(torch.mm(x, self.weight.T) + self.bias.unsqueeze(0))\n",
    "            else:\n",
    "                y = activation(torch.mm(x, self.weight.T))\n",
    "        max_idx_list =[]\n",
    "        max_idx_list = classifier_head(y, self.direction_weights, labels)\n",
    "        '''\n",
    "        for dat in range(y.shape[0]):\n",
    "            max = -np.inf\n",
    "            max_idx = 0\n",
    "            for i in range(self.num_classes):\n",
    "                cos_sim = cos_similarity(y[dat, :].unsqueeze(0), self.directions[i].reshape(1, -1))\n",
    "                if cos_sim > max:\n",
    "                    max = cos_sim\n",
    "                    max_idx = i\n",
    "            max_idx_list.append(max_idx)\n",
    "        '''\n",
    "        return torch.tensor(max_idx_list, device=device), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dims_list, bias, epochs, lr, device):\n",
    "        super(Net, self).__init__()\n",
    "        self.dims_list = dims_list\n",
    "        self.bias = bias\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "        self.layers = []\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "        global initial\n",
    "        for d in range(len(self.dims_list) - 1):\n",
    "            print(f\"Initialization {d + 1} / {len(self.dims_list) - 1}\")\n",
    "            self.layers += [Layer(self.dims_list[d], self.dims_list[d + 1], self.bias, self.device, self.lr)]\n",
    "            print(\"Complete\\n\")\n",
    "        \n",
    "    def train(self, train_loader, test_loader):\n",
    "        layer_loss_list = []\n",
    "        acc_train = []\n",
    "        acc_test = []\n",
    "        layer_w = [[] for _ in range(len(self.dims_list) - 1)]\n",
    "        \n",
    "        for i in range(len(self.layers)):\n",
    "            layer_loss_list.append([])\n",
    "        pbar = tqdm(total = self.epochs * len(train_loader) * len(self.layers), \n",
    "                    desc = f\"Training\", position = 0, leave = True)\n",
    "        \n",
    "        # Test the network\n",
    "        with torch.no_grad():\n",
    "           \n",
    "            for i in range(len(self.layers)):\n",
    "                layer_w[i].append(torch.norm(self.layers[i].weight, p=2).item())\n",
    "            acc_train.append(net.test(trainloader))\n",
    "            acc_test.append(net.test(testloader))\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            if epoch and not (epoch % 10): \n",
    "                # learning rate decay\n",
    "                for i in range(len(self.layers)):\n",
    "                    self.layers[i].lr = self.layers[i].lr - 0.1\n",
    "                    print('lr decreased to ', self.layers[i].lr)\n",
    "            \n",
    "            loss_agg = [0] * len(self.layers)\n",
    "            for dat in train_loader:\n",
    "                x, label = dat\n",
    "                x = x.to(device)\n",
    "                label = label.to(device)\n",
    "                for i in range(len(self.layers)):\n",
    "                    \n",
    "                    loss, y = self.layers[i].train(x, label)\n",
    "                    self.layers[i].zero_grad(set_to_none=True)\n",
    "                    x = y.detach()\n",
    "                    loss_agg[i] += loss / len(train_loader)\n",
    "                    del y\n",
    "                    pbar.update(1)\n",
    "            pbar.set_postfix(epoch = epoch + 1, loss = loss_agg)\n",
    "            for i in range(len(self.layers)):\n",
    "                layer_loss_list[i].append(loss_agg[i])\n",
    "                \n",
    "        # Test the network\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(self.layers)):\n",
    "                layer_w[i].append(torch.norm(self.layers[i].weight, p=2).item())\n",
    "            acc_train.append(net.test(train_loader))\n",
    "            acc_test.append(net.test(test_loader))  \n",
    "                \n",
    "        pbar.close()\n",
    "        return [layer_loss_list, acc_train, acc_test, layer_w]\n",
    "    \n",
    "    def test(self, data_loader):\n",
    "        all_accuracy = []\n",
    "        correct = [0 for _ in range(len(self.layers))]\n",
    "        total = [0 for _ in range(len(self.layers))]\n",
    "        for dat in data_loader:\n",
    "            x = dat[0]\n",
    "            label = dat[1]\n",
    "            x = x.to(device)\n",
    "            label = label.to(device)\n",
    "            num = label\n",
    "            preds = []\n",
    "            \n",
    "            for i in range(len(self.layers)):\n",
    "                pred, x = self.layers[i].test(x, label)\n",
    "                preds.append(pred)\n",
    "            \n",
    "            for i in range(len(preds)):\n",
    "                correct[i] += (preds[i] == num).sum().item()\n",
    "                total[i] += num.shape[0]\n",
    "                \n",
    "        all_accuracy.append(np.array(correct) / total[-1])\n",
    "        return all_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_transform = transforms.Lambda(lambda x: x.view(x.size(0), -1).squeeze())\n",
    "'''\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    flatten_transform\n",
    "])\n",
    "'''\n",
    "\n",
    "# # Define data transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.,), (0.5,)),\n",
    "#     flatten_transform\n",
    "# ])\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), flatten_transform]) # this normalizes to [0,1]\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./../../../Data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./../../../Data', train=False, download=True, transform=transform)\n",
    "batch_size = 50\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle = False)\n",
    "\n",
    "# full_data_set = torch.utils.data.ConcatDataset([trainset, testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1 / 2\n",
      "Complete\n",
      "\n",
      "Initialization 2 / 2\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 24114/480000 [00:31<08:52, 856.64it/s, epoch=10, loss=[0.3561824440956118, 0.23230"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.4\n",
      "lr decreased to  2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 48143/480000 [01:00<08:33, 840.80it/s, epoch=20, loss=[0.3515272478759292, 0.22684"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.3\n",
      "lr decreased to  2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 72165/480000 [01:29<07:40, 885.29it/s, epoch=30, loss=[0.34952623223265006, 0.2125"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.1999999999999997\n",
      "lr decreased to  2.1999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 96116/480000 [01:57<07:27, 857.54it/s, epoch=40, loss=[0.3483367256075153, 0.20979"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.0999999999999996\n",
      "lr decreased to  2.0999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 120100/480000 [02:26<07:49, 766.71it/s, epoch=50, loss=[0.3474910945942006, 0.2077"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.9999999999999996\n",
      "lr decreased to  1.9999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 144137/480000 [02:55<06:44, 830.28it/s, epoch=60, loss=[0.3466495410352947, 0.2061"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.8999999999999995\n",
      "lr decreased to  1.8999999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 168084/480000 [03:23<06:20, 818.99it/s, epoch=70, loss=[0.3461094703276954, 0.2050"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.7999999999999994\n",
      "lr decreased to  1.7999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 192129/480000 [03:52<05:33, 864.03it/s, epoch=80, loss=[0.34564033615092427, 0.204"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.6999999999999993\n",
      "lr decreased to  1.6999999999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 216105/480000 [04:21<05:12, 843.67it/s, epoch=90, loss=[0.34520834505558, 0.203835"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.5999999999999992\n",
      "lr decreased to  1.5999999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 240125/480000 [04:50<04:39, 858.41it/s, epoch=100, loss=[0.3447985035429403, 0.203"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.4999999999999991\n",
      "lr decreased to  1.4999999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 264097/480000 [05:18<04:12, 854.38it/s, epoch=110, loss=[0.3444007125993567, 0.202"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.399999999999999\n",
      "lr decreased to  1.399999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 288131/480000 [05:46<03:39, 872.29it/s, epoch=120, loss=[0.3440093382944667, 0.202"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.299999999999999\n",
      "lr decreased to  1.299999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 312097/480000 [06:16<03:21, 833.61it/s, epoch=130, loss=[0.34361588155229944, 0.20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.1999999999999988\n",
      "lr decreased to  1.1999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 336152/480000 [06:45<02:56, 814.96it/s, epoch=140, loss=[0.3431191883981227, 0.200"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.0999999999999988\n",
      "lr decreased to  1.0999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 360101/480000 [07:15<02:41, 740.82it/s, epoch=150, loss=[0.34267425681153896, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.9999999999999988\n",
      "lr decreased to  0.9999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 384165/480000 [07:45<01:53, 847.01it/s, epoch=160, loss=[0.3421789552023015, 0.196"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.8999999999999988\n",
      "lr decreased to  0.8999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 408091/480000 [08:13<01:28, 812.91it/s, epoch=170, loss=[0.34170375108718937, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.7999999999999988\n",
      "lr decreased to  0.7999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 432091/480000 [08:43<00:59, 809.02it/s, epoch=180, loss=[0.34121362557013885, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.6999999999999988\n",
      "lr decreased to  0.6999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 456144/480000 [09:13<00:31, 769.09it/s, epoch=190, loss=[0.3406966129938758, 0.195"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.5999999999999989\n",
      "lr decreased to  0.5999999999999989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 480000/480000 [09:47<00:00, 816.82it/s, epoch=200, loss=[0.34014328057567267, 0.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1 / 2\n",
      "Complete\n",
      "\n",
      "Initialization 2 / 2\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 24131/480000 [00:34<09:28, 801.53it/s, epoch=10, loss=[0.3441522765407955, 0.23816"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.4\n",
      "lr decreased to  2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 48154/480000 [01:07<09:22, 767.86it/s, epoch=20, loss=[0.33956024152537184, 0.2104"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.3\n",
      "lr decreased to  2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 72106/480000 [01:39<08:53, 764.27it/s, epoch=30, loss=[0.3372780714929103, 0.20679"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.1999999999999997\n",
      "lr decreased to  2.1999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 96112/480000 [02:11<08:58, 713.22it/s, epoch=40, loss=[0.33613164422412745, 0.2035"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.0999999999999996\n",
      "lr decreased to  2.0999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 120089/480000 [02:42<07:51, 762.85it/s, epoch=50, loss=[0.3353217093646527, 0.2026"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.9999999999999996\n",
      "lr decreased to  1.9999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 144101/480000 [03:13<06:52, 814.50it/s, epoch=60, loss=[0.3346425771216551, 0.1997"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.8999999999999995\n",
      "lr decreased to  1.8999999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 168088/480000 [03:45<07:15, 715.92it/s, epoch=70, loss=[0.33404268259803466, 0.199"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.7999999999999994\n",
      "lr decreased to  1.7999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 192079/480000 [04:16<06:17, 762.53it/s, epoch=80, loss=[0.33339400798082314, 0.198"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.6999999999999993\n",
      "lr decreased to  1.6999999999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 216083/480000 [04:46<05:30, 798.56it/s, epoch=90, loss=[0.3329100214441613, 0.1973"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.5999999999999992\n",
      "lr decreased to  1.5999999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 240121/480000 [05:16<05:12, 766.66it/s, epoch=100, loss=[0.33250738526384044, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.4999999999999991\n",
      "lr decreased to  1.4999999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 264083/480000 [05:45<04:26, 810.96it/s, epoch=110, loss=[0.33212064060072066, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.399999999999999\n",
      "lr decreased to  1.399999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 288139/480000 [06:15<03:55, 814.84it/s, epoch=120, loss=[0.33174044139683295, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.299999999999999\n",
      "lr decreased to  1.299999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 312123/480000 [06:45<03:32, 790.30it/s, epoch=130, loss=[0.33136263837416946, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.1999999999999988\n",
      "lr decreased to  1.1999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 336144/480000 [07:15<02:57, 808.67it/s, epoch=140, loss=[0.3309768450508511, 0.195"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.0999999999999988\n",
      "lr decreased to  1.0999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 360154/480000 [07:44<02:23, 832.30it/s, epoch=150, loss=[0.33058120988309353, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.9999999999999988\n",
      "lr decreased to  0.9999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 384127/480000 [08:14<02:03, 776.72it/s, epoch=160, loss=[0.3301698070019486, 0.194"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.8999999999999988\n",
      "lr decreased to  0.8999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 408111/480000 [08:43<01:34, 763.20it/s, epoch=170, loss=[0.3297380407154556, 0.194"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.7999999999999988\n",
      "lr decreased to  0.7999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 432091/480000 [09:14<01:07, 714.98it/s, epoch=180, loss=[0.32925293947259543, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.6999999999999988\n",
      "lr decreased to  0.6999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 456140/480000 [09:45<00:31, 756.28it/s, epoch=190, loss=[0.32872267526884863, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.5999999999999989\n",
      "lr decreased to  0.5999999999999989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 480000/480000 [10:19<00:00, 775.26it/s, epoch=200, loss=[0.32811354969938644, 0.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1 / 2\n",
      "Complete\n",
      "\n",
      "Initialization 2 / 2\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 24113/480000 [00:34<09:51, 771.28it/s, epoch=10, loss=[0.35487181750436636, 0.2872"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.4\n",
      "lr decreased to  2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 48109/480000 [01:04<08:56, 805.09it/s, epoch=20, loss=[0.3503768819570536, 0.28526"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.3\n",
      "lr decreased to  2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 72141/480000 [01:35<09:11, 740.01it/s, epoch=30, loss=[0.3477618865172068, 0.27593"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.1999999999999997\n",
      "lr decreased to  2.1999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 96133/480000 [02:05<07:39, 835.59it/s, epoch=40, loss=[0.34644333941241073, 0.2572"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.0999999999999996\n",
      "lr decreased to  2.0999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 120141/480000 [02:36<07:45, 773.34it/s, epoch=50, loss=[0.3456436532487466, 0.2571"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.9999999999999996\n",
      "lr decreased to  1.9999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 144116/480000 [03:06<07:14, 773.00it/s, epoch=60, loss=[0.34505395464599115, 0.257"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.8999999999999995\n",
      "lr decreased to  1.8999999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 168102/480000 [03:37<06:55, 750.06it/s, epoch=70, loss=[0.3445688636600976, 0.2553"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.7999999999999994\n",
      "lr decreased to  1.7999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 192089/480000 [04:07<06:20, 756.61it/s, epoch=80, loss=[0.34415216612319166, 0.254"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.6999999999999993\n",
      "lr decreased to  1.6999999999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 216085/480000 [04:38<05:41, 773.43it/s, epoch=90, loss=[0.3437537362178167, 0.2511"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.5999999999999992\n",
      "lr decreased to  1.5999999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 240134/480000 [05:09<05:45, 694.78it/s, epoch=100, loss=[0.343397381231188, 0.2504"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.4999999999999991\n",
      "lr decreased to  1.4999999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 264096/480000 [05:44<05:13, 688.66it/s, epoch=110, loss=[0.34306408400336924, 0.25"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.399999999999999\n",
      "lr decreased to  1.399999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 288121/480000 [06:17<05:17, 603.84it/s, epoch=120, loss=[0.3426495249321066, 0.250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.299999999999999\n",
      "lr decreased to  1.299999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 312105/480000 [06:51<04:04, 685.31it/s, epoch=130, loss=[0.34232116344074365, 0.24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.1999999999999988\n",
      "lr decreased to  1.1999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 336122/480000 [07:26<03:24, 702.38it/s, epoch=140, loss=[0.34199631700913136, 0.24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.0999999999999988\n",
      "lr decreased to  1.0999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 360149/480000 [08:01<02:35, 773.19it/s, epoch=150, loss=[0.3416855694105228, 0.248"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.9999999999999988\n",
      "lr decreased to  0.9999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 384137/480000 [08:34<02:10, 732.55it/s, epoch=160, loss=[0.34137428847452, 0.24659"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.8999999999999988\n",
      "lr decreased to  0.8999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 408122/480000 [09:07<01:32, 773.22it/s, epoch=170, loss=[0.3410591076314452, 0.246"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.7999999999999988\n",
      "lr decreased to  0.7999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 432126/480000 [09:40<01:01, 778.80it/s, epoch=180, loss=[0.34073520968357734, 0.24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.6999999999999988\n",
      "lr decreased to  0.6999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 456111/480000 [10:12<00:32, 738.51it/s, epoch=190, loss=[0.3404021689295771, 0.246"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.5999999999999989\n",
      "lr decreased to  0.5999999999999989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 480000/480000 [10:49<00:00, 739.30it/s, epoch=200, loss=[0.34006077103316745, 0.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1 / 2\n",
      "Complete\n",
      "\n",
      "Initialization 2 / 2\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 24081/480000 [00:36<10:35, 716.97it/s, epoch=10, loss=[0.3547314678629237, 0.27464"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.4\n",
      "lr decreased to  2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 48113/480000 [01:10<09:59, 721.00it/s, epoch=20, loss=[0.34902509873112025, 0.2664"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.3\n",
      "lr decreased to  2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 72119/480000 [01:44<09:08, 744.26it/s, epoch=30, loss=[0.34685662460823824, 0.2492"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.1999999999999997\n",
      "lr decreased to  2.1999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 96081/480000 [02:17<08:40, 737.63it/s, epoch=40, loss=[0.3456349778920406, 0.24733"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.0999999999999996\n",
      "lr decreased to  2.0999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 120097/480000 [02:50<08:18, 721.66it/s, epoch=50, loss=[0.34466944443682856, 0.232"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.9999999999999996\n",
      "lr decreased to  1.9999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 144145/480000 [03:25<07:30, 745.62it/s, epoch=60, loss=[0.3440371569246058, 0.2281"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.8999999999999995\n",
      "lr decreased to  1.8999999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 168136/480000 [04:00<07:30, 692.10it/s, epoch=70, loss=[0.34350567889710293, 0.226"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.7999999999999994\n",
      "lr decreased to  1.7999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 192099/480000 [04:34<06:57, 688.89it/s, epoch=80, loss=[0.34304589527348706, 0.225"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.6999999999999993\n",
      "lr decreased to  1.6999999999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 216121/480000 [05:07<06:18, 696.43it/s, epoch=90, loss=[0.3426215178271137, 0.2238"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.5999999999999992\n",
      "lr decreased to  1.5999999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 240125/480000 [05:41<05:24, 738.80it/s, epoch=100, loss=[0.3422091176360848, 0.222"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.4999999999999991\n",
      "lr decreased to  1.4999999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 264117/480000 [06:15<04:41, 767.18it/s, epoch=110, loss=[0.34176856438318914, 0.22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.399999999999999\n",
      "lr decreased to  1.399999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 288115/480000 [06:48<04:25, 721.58it/s, epoch=120, loss=[0.34137105380495414, 0.22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.299999999999999\n",
      "lr decreased to  1.299999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 312155/480000 [07:22<03:35, 778.72it/s, epoch=130, loss=[0.340850746830305, 0.2215"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.1999999999999988\n",
      "lr decreased to  1.1999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 336114/480000 [07:56<03:56, 609.63it/s, epoch=140, loss=[0.3404648749033605, 0.220"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.0999999999999988\n",
      "lr decreased to  1.0999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 360069/480000 [08:31<02:59, 669.03it/s, epoch=150, loss=[0.3400794092814128, 0.220"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.9999999999999988\n",
      "lr decreased to  0.9999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 384084/480000 [09:05<02:02, 784.68it/s, epoch=160, loss=[0.3396755628287793, 0.219"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.8999999999999988\n",
      "lr decreased to  0.8999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 408101/480000 [09:39<01:39, 724.13it/s, epoch=170, loss=[0.33920790709555104, 0.21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.7999999999999988\n",
      "lr decreased to  0.7999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 432097/480000 [10:13<01:02, 766.80it/s, epoch=180, loss=[0.33876452095806636, 0.21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.6999999999999988\n",
      "lr decreased to  0.6999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 456108/480000 [10:45<00:30, 778.45it/s, epoch=190, loss=[0.33828947968780926, 0.21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.5999999999999989\n",
      "lr decreased to  0.5999999999999989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 480000/480000 [11:22<00:00, 703.55it/s, epoch=200, loss=[0.33776932500302764, 0.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1 / 2\n",
      "Complete\n",
      "\n",
      "Initialization 2 / 2\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 24127/480000 [00:37<11:16, 673.98it/s, epoch=10, loss=[0.35416261459390314, 0.2805"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.4\n",
      "lr decreased to  2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 48101/480000 [01:10<09:43, 740.41it/s, epoch=20, loss=[0.34859205807248866, 0.2596"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.3\n",
      "lr decreased to  2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 72080/480000 [01:45<09:43, 699.61it/s, epoch=30, loss=[0.34659073628485243, 0.2505"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.1999999999999997\n",
      "lr decreased to  2.1999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 96115/480000 [02:20<08:59, 711.94it/s, epoch=40, loss=[0.3453984050701065, 0.24484"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.0999999999999996\n",
      "lr decreased to  2.0999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 120092/480000 [02:54<08:55, 672.65it/s, epoch=50, loss=[0.3445744137962654, 0.2442"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.9999999999999996\n",
      "lr decreased to  1.9999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 144133/480000 [03:26<07:10, 780.57it/s, epoch=60, loss=[0.34391107757886225, 0.241"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.8999999999999995\n",
      "lr decreased to  1.8999999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 168128/480000 [03:58<06:56, 749.41it/s, epoch=70, loss=[0.34341941354175454, 0.238"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.7999999999999994\n",
      "lr decreased to  1.7999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 192104/480000 [04:30<05:54, 812.82it/s, epoch=80, loss=[0.3429883492241302, 0.2367"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.6999999999999993\n",
      "lr decreased to  1.6999999999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 216072/480000 [05:03<06:16, 700.24it/s, epoch=90, loss=[0.3425185816735031, 0.2387"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.5999999999999992\n",
      "lr decreased to  1.5999999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 240098/480000 [05:37<05:22, 743.05it/s, epoch=100, loss=[0.34203396526475704, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.4999999999999991\n",
      "lr decreased to  1.4999999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 264065/480000 [06:11<04:42, 765.22it/s, epoch=110, loss=[0.3416070530066896, 0.232"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.399999999999999\n",
      "lr decreased to  1.399999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 288093/480000 [06:44<04:19, 738.50it/s, epoch=120, loss=[0.34115083744128555, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.299999999999999\n",
      "lr decreased to  1.299999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 312142/480000 [07:17<03:50, 727.83it/s, epoch=130, loss=[0.3407800513009231, 0.230"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.1999999999999988\n",
      "lr decreased to  1.1999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 336116/480000 [07:49<03:15, 737.24it/s, epoch=140, loss=[0.34043524414300996, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.0999999999999988\n",
      "lr decreased to  1.0999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 360101/480000 [08:23<03:07, 638.46it/s, epoch=150, loss=[0.3400971301148337, 0.230"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.9999999999999988\n",
      "lr decreased to  0.9999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 384066/480000 [08:57<02:35, 618.32it/s, epoch=160, loss=[0.3397557555387423, 0.230"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.8999999999999988\n",
      "lr decreased to  0.8999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 408137/480000 [09:31<01:31, 781.44it/s, epoch=170, loss=[0.33940594022472675, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.7999999999999988\n",
      "lr decreased to  0.7999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 432100/480000 [10:04<01:02, 765.34it/s, epoch=180, loss=[0.3390451100468638, 0.228"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.6999999999999988\n",
      "lr decreased to  0.6999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 456131/480000 [10:38<00:31, 748.27it/s, epoch=190, loss=[0.338668550848961, 0.2252"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.5999999999999989\n",
      "lr decreased to  0.5999999999999989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 480000/480000 [11:15<00:00, 710.49it/s, epoch=200, loss=[0.33827623739838586, 0.22\n"
     ]
    }
   ],
   "source": [
    "# ratio = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "ratio = [0.2]\n",
    "test_acc = []\n",
    "train_acc = []\n",
    "w_layers = []\n",
    "loss = []\n",
    "\n",
    "num_runs = 5\n",
    "\n",
    "# for r in ratio:\n",
    "    # print(f\"train ratio: {r}\")\n",
    "'''    \n",
    "test_size = int(r * len(full_data_set))\n",
    "train_size = len(full_data_set) - test_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_data_set, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for training set\n",
    "trainloader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "\n",
    "# Create DataLoader for test set\n",
    "testloader = DataLoader(test_dataset, batch_size = 64, shuffle=False)\n",
    "'''\n",
    "for _ in range(num_runs):\n",
    "    \n",
    "    dims_list = [784, 1024, 10]\n",
    "    # dims_list = [784, 1000, 34]\n",
    "    bias = True\n",
    "    epochs = 200\n",
    "    lr  = 2.5\n",
    "    num_classes = 10\n",
    "    net = Net(dims_list, bias, epochs, lr, device)\n",
    "    \n",
    "    # Train the network\n",
    "    layer_loss_list = net.train(trainloader, testloader)\n",
    "    \n",
    "    # plot_losses(layer_loss_list[0])\n",
    "    \n",
    "    '''\n",
    "    # Test the network\n",
    "    acc_train = net.test(trainloader)\n",
    "    print(f\"Train accuracy: {acc_train * 100:.2f}%\")\n",
    "    \n",
    "    acc_test = net.test(testloader)\n",
    "    print(f\"Test accuracy: {acc_test * 100:.2f}%\")\n",
    "    '''\n",
    "    loss.append(layer_loss_list[0])\n",
    "    train_acc.append(layer_loss_list[1])\n",
    "    test_acc.append(layer_loss_list[2])\n",
    "    w_layers.append(layer_loss_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[array([0.0911, 0.0831])], [array([0.9088, 0.9355])]], [[array([0.1112, 0.0903])], [array([0.9092, 0.9343])]], [[array([0.127 , 0.0365])], [array([0.9095, 0.6759])]], [[array([0.0937, 0.0815])], [array([0.9077, 0.88  ])]], [[array([0.133 , 0.0966])], [array([0.9102, 0.9091])]]]\n",
      "0.9355\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)\n",
    "print(np.max(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[array([0.08425   , 0.08618333])], [array([0.91215   , 0.94918333])]], [[array([0.11678333, 0.09033333])], [array([0.91266667, 0.94681667])]], [[array([0.12925   , 0.03968333])], [array([0.91336667, 0.68178333])]], [[array([0.0952, 0.0874])], [array([0.91108333, 0.89215   ])]], [[array([0.13366667, 0.09918333])], [array([0.91345   , 0.91698333])]]]\n",
      "0.9491833333333334\n"
     ]
    }
   ],
   "source": [
    "print(train_acc)\n",
    "print(np.max(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./../new_data/ablation_gaussiandir_mnist_train_acc.npy\", np.array(train_acc))\n",
    "np.save(\"./../new_data/ablation_gaussiandir_mnist_test_acc.npy\", np.array(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
