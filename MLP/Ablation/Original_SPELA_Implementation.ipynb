{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './../../../Models')\n",
    "from sphere_points import generate_points\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import SGD\n",
    "from torch.nn.functional import normalize, one_hot\n",
    "# import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    losses = np.array(losses)\n",
    "    n_dims, epochs = losses.shape\n",
    "    plt.figure(figsize = (12, 5))\n",
    "    for l in range(n_dims):\n",
    "        plt.subplot(1, n_dims, l + 1)\n",
    "        plt.plot(1 + np.arange(epochs), losses[l])\n",
    "        plt.title(f\"Layer {l + 1} Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loss = nn.CrossEntropyLoss()\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_head_train(inp_embedding, classifier_weights, labels):\n",
    "    # model_loss = nn.CrossEntropyLoss()\n",
    "    inp_embedding = normalize(inp_embedding, p=2, dim=-1)\n",
    "    classifier_output = torch.mm(inp_embedding, classifier_weights)\n",
    "    # classifier_output = 1 - (torch.acos(classifier_output)/np.pi)\n",
    "    classifier_output = classifier_output * one_hot(labels, num_classes = num_classes).type(torch.float32)\n",
    "    # classifier_output = torch.softmax(classifier_output, dim=-1)\n",
    "    # loss = model_loss(classifier_output, one_hot(labels, num_classes = num_classes).type(torch.float32))\n",
    "    theta = 1\n",
    "    loss = torch.mean(torch.log(2 - (theta * torch.sum(classifier_output,1))))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_head(inp_embedding, classifier_weights, labels):\n",
    "    inp_embedding = normalize(inp_embedding, p=2, dim=-1)\n",
    "    classifier_output = torch.mm(inp_embedding, classifier_weights)\n",
    "    # classifier_output = 1 - (torch.acos(classifier_output)/np.pi)\n",
    "    # classifier_output = torch.softmax(classifier_output, dim=-1)\n",
    "    # loss = model_loss(classifier_output, one_hot(labels, num_classes = num_classes).type(torch.float32))\n",
    "    return torch.argmax(classifier_output, dim=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = None\n",
    "# num_classes = 10\n",
    "\n",
    "# Data dimension\n",
    "# (num_data, num_features) => no dimension for batch size please\n",
    "class Layer(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias, device, lr, apply_dropout=False):\n",
    "        super().__init__(in_features, out_features, bias, device)\n",
    "        self.out_features = out_features\n",
    "        self.bias_flag = bias\n",
    "        self.lr = lr\n",
    "        self.num_classes = num_classes\n",
    "        self.dimension = out_features\n",
    "        # self.activation = DyT(1)\n",
    "        # self.activation = nn.LeakyReLU(negative_slope=0.001)\n",
    "        # self.leaky_relu = nn.LeakyReLU(negative_slope=0.001)\n",
    "        # self.activation = nn.GELU()\n",
    "        # self.opt = Adam(self.parameters(), lr = self.lr)\n",
    "        # self.opt = SGD(self.parameters(), lr=self.lr, momentum=0.9)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.opt, \n",
    "        #                                                       milestones=[60], gamma=0.1)\n",
    "        # nn.init.kaiming_normal_(self.weight, mode='fan_in')\n",
    "        \n",
    "        fc1_limit = np.sqrt(6.0 / in_features)\n",
    "        torch.nn.init.uniform_(self.weight, a=-fc1_limit, b=fc1_limit)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.apply_dropout = apply_dropout\n",
    "        global initial\n",
    "        self.directions = generate_points(self.num_classes, self.dimension, steps = 10000)\n",
    "        initial = np.array(self.directions)\n",
    "        self.directions = [torch.tensor(t, dtype = torch.float32).to(device) for t in self.directions]\n",
    "        self.direction_weights = torch.zeros((len(self.directions[0]), len(self.directions)), device=device, \n",
    "                                             requires_grad=False)\n",
    "        for i in range(len(self.directions)):\n",
    "            self.direction_weights[:, i] = normalize(self.directions[i], p = 2, dim=-1)\n",
    "\n",
    "    def train(self, x, labels):\n",
    "        if self.apply_dropout:\n",
    "            x = self.dropout(x)\n",
    "        # activation = nn.ELU()\n",
    "        activation = nn.LeakyReLU(negative_slope=0.001)\n",
    "        # activation = nn.Tanh()\n",
    "        # activation = self.activation\n",
    "        # opt = SGD(self.parameters(), lr=self.lr, momentum=0.9)\n",
    "        opt = SGD(self.parameters(), lr=self.lr)\n",
    "        # activation = nn.GELU()\n",
    "        # activation = nn.ReLU()\n",
    "        # opt = Adam(self.parameters(), lr=self.lr)\n",
    "        # print(f\"gpu used {torch.cuda.max_memory_allocated(device=None)} memory\")\n",
    "        if self.bias_flag:\n",
    "            y = activation(torch.mm(x, self.weight.T) + self.bias.unsqueeze(0))\n",
    "        else:\n",
    "            y = activation(torch.mm(x, self.weight.T))\n",
    "        # if self.apply_dropout:\n",
    "        #     x = self.dropout(x)\n",
    "        # y = self.forward(x) # shape: (num_data, out_features)\n",
    "        '''\n",
    "        y = normalize(y, p = 2, dim = 1)\n",
    "        '''\n",
    "        # import pdb;pdb.set_trace()\n",
    "        loss = classifier_head_train(y, self.direction_weights, labels)\n",
    "        \n",
    "        '''\n",
    "        directions = torch.zeros_like(y)\n",
    "        for i in range(y.shape[0]):\n",
    "            directions[i, :] = self.directions[label[i]]\n",
    "        \n",
    "        loss = loss_layer(y, directions)\n",
    "        '''\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward(retain_graph = False)\n",
    "        opt.step()\n",
    "        # self.scheduler.step()\n",
    "        \n",
    "        # normalize the directions\n",
    "        # self.directions.data = normalize(self.directions.data, p = 2, dim = 1)\n",
    "\n",
    "        return loss.detach().item(), y\n",
    "    \n",
    "    def test(self, x, labels):\n",
    "        with torch.no_grad():\n",
    "            # activation = nn.ELU()\n",
    "            # y = self.forward(x)\n",
    "            activation = nn.LeakyReLU(negative_slope=0.001)\n",
    "            # activation = nn.ReLU()\n",
    "            # activation = nn.GELU()\n",
    "            # activation = nn.Tanh()\n",
    "            # activation = self.activation\n",
    "            if self.bias_flag:\n",
    "                y = activation(torch.mm(x, self.weight.T) + self.bias.unsqueeze(0))\n",
    "            else:\n",
    "                y = activation(torch.mm(x, self.weight.T))\n",
    "        max_idx_list =[]\n",
    "        max_idx_list = classifier_head(y, self.direction_weights, labels)\n",
    "        '''\n",
    "        for dat in range(y.shape[0]):\n",
    "            max = -np.inf\n",
    "            max_idx = 0\n",
    "            for i in range(self.num_classes):\n",
    "                cos_sim = cos_similarity(y[dat, :].unsqueeze(0), self.directions[i].reshape(1, -1))\n",
    "                if cos_sim > max:\n",
    "                    max = cos_sim\n",
    "                    max_idx = i\n",
    "            max_idx_list.append(max_idx)\n",
    "        '''\n",
    "        return torch.tensor(max_idx_list, device=device), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dims_list, bias, epochs, lr, device):\n",
    "        super(Net, self).__init__()\n",
    "        self.dims_list = dims_list\n",
    "        self.bias = bias\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "        self.layers = []\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "        global initial\n",
    "        for d in range(len(self.dims_list) - 1):\n",
    "            print(f\"Initialization {d + 1} / {len(self.dims_list) - 1}\")\n",
    "            self.layers += [Layer(self.dims_list[d], self.dims_list[d + 1], self.bias, self.device, self.lr)]\n",
    "            print(\"Complete\\n\")\n",
    "        \n",
    "    def train(self, train_loader, test_loader):\n",
    "        layer_loss_list = []\n",
    "        acc_train = []\n",
    "        acc_test = []\n",
    "        layer_w = [[] for _ in range(len(self.dims_list) - 1)]\n",
    "        \n",
    "        for i in range(len(self.layers)):\n",
    "            layer_loss_list.append([])\n",
    "        pbar = tqdm(total = self.epochs * len(train_loader) * len(self.layers), \n",
    "                    desc = f\"Training\", position = 0, leave = True)\n",
    "        \n",
    "        # Test the network\n",
    "        with torch.no_grad():\n",
    "           \n",
    "            for i in range(len(self.layers)):\n",
    "                layer_w[i].append(torch.norm(self.layers[i].weight, p=2).item())\n",
    "            acc_train.append(net.test(trainloader))\n",
    "            acc_test.append(net.test(testloader))\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            if epoch and not (epoch % 10): \n",
    "                # learning rate decay\n",
    "                for i in range(len(self.layers)):\n",
    "                    self.layers[i].lr = self.layers[i].lr - 0.1\n",
    "                    print('lr decreased to ', self.layers[i].lr)\n",
    "            \n",
    "            loss_agg = [0] * len(self.layers)\n",
    "            for dat in train_loader:\n",
    "                x, label = dat\n",
    "                x = x.to(device)\n",
    "                label = label.to(device)\n",
    "                for i in range(len(self.layers)):\n",
    "                    \n",
    "                    loss, y = self.layers[i].train(x, label)\n",
    "                    self.layers[i].zero_grad(set_to_none=True)\n",
    "                    x = y.detach()\n",
    "                    loss_agg[i] += loss / len(train_loader)\n",
    "                    del y\n",
    "                    pbar.update(1)\n",
    "            pbar.set_postfix(epoch = epoch + 1, loss = loss_agg)\n",
    "            for i in range(len(self.layers)):\n",
    "                layer_loss_list[i].append(loss_agg[i])\n",
    "                \n",
    "        # Test the network\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(self.layers)):\n",
    "                layer_w[i].append(torch.norm(self.layers[i].weight, p=2).item())\n",
    "            acc_train.append(net.test(train_loader))\n",
    "            acc_test.append(net.test(test_loader))  \n",
    "                \n",
    "        pbar.close()\n",
    "        return [layer_loss_list, acc_train, acc_test, layer_w]\n",
    "    \n",
    "    def test(self, data_loader):\n",
    "        all_accuracy = []\n",
    "        correct = [0 for _ in range(len(self.layers))]\n",
    "        total = [0 for _ in range(len(self.layers))]\n",
    "        for dat in data_loader:\n",
    "            x = dat[0]\n",
    "            label = dat[1]\n",
    "            x = x.to(device)\n",
    "            label = label.to(device)\n",
    "            num = label\n",
    "            preds = []\n",
    "            \n",
    "            for i in range(len(self.layers)):\n",
    "                pred, x = self.layers[i].test(x, label)\n",
    "                preds.append(pred)\n",
    "            \n",
    "            for i in range(len(preds)):\n",
    "                correct[i] += (preds[i] == num).sum().item()\n",
    "                total[i] += num.shape[0]\n",
    "                \n",
    "        all_accuracy.append(np.array(correct) / total[-1])\n",
    "        return all_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_transform = transforms.Lambda(lambda x: x.view(x.size(0), -1).squeeze())\n",
    "'''\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    flatten_transform\n",
    "])\n",
    "'''\n",
    "\n",
    "# # Define data transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.,), (0.5,)),\n",
    "#     flatten_transform\n",
    "# ])\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), flatten_transform]) # this normalizes to [0,1]\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./../../../Data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./../../../Data', train=False, download=True, transform=transform)\n",
    "batch_size = 50\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle = False)\n",
    "\n",
    "# full_data_set = torch.utils.data.ConcatDataset([trainset, testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1 / 2\n",
      "Complete\n",
      "\n",
      "Initialization 2 / 2\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 24113/480000 [00:31<09:33, 795.19it/s, epoch=10, loss=[0.35989250689744895, 0.3110"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.4\n",
      "lr decreased to  2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 48157/480000 [01:00<07:58, 903.09it/s, epoch=20, loss=[0.35386967102686545, 0.3214"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.3\n",
      "lr decreased to  2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 72161/480000 [01:28<08:06, 837.48it/s, epoch=30, loss=[0.3516720188905798, 0.29584"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.1999999999999997\n",
      "lr decreased to  2.1999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 96137/480000 [01:57<07:38, 836.58it/s, epoch=40, loss=[0.3501994325965645, 0.29454"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.0999999999999996\n",
      "lr decreased to  2.0999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 120171/480000 [02:25<06:55, 865.49it/s, epoch=50, loss=[0.34942907457550426, 0.294"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.9999999999999996\n",
      "lr decreased to  1.9999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 144141/480000 [02:53<06:28, 865.30it/s, epoch=60, loss=[0.34875621465345197, 0.293"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.8999999999999995\n",
      "lr decreased to  1.8999999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 168143/480000 [03:21<06:27, 805.10it/s, epoch=70, loss=[0.34833494683106725, 0.294"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.7999999999999994\n",
      "lr decreased to  1.7999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 192149/480000 [03:50<05:34, 861.50it/s, epoch=80, loss=[0.34803126749893065, 0.295"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.6999999999999993\n",
      "lr decreased to  1.6999999999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 216097/480000 [04:19<05:11, 846.56it/s, epoch=90, loss=[0.34777008267740395, 0.292"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.5999999999999992\n",
      "lr decreased to  1.5999999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 240138/480000 [04:48<04:41, 851.24it/s, epoch=100, loss=[0.34755338758230137, 0.29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.4999999999999991\n",
      "lr decreased to  1.4999999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 264154/480000 [05:16<04:09, 864.05it/s, epoch=110, loss=[0.34737006485462285, 0.29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.399999999999999\n",
      "lr decreased to  1.399999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 288117/480000 [05:43<03:45, 852.55it/s, epoch=120, loss=[0.34720926962792886, 0.29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.299999999999999\n",
      "lr decreased to  1.299999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 312153/480000 [06:12<03:03, 913.33it/s, epoch=130, loss=[0.3470644739021852, 0.291"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.1999999999999988\n",
      "lr decreased to  1.1999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 336120/480000 [06:40<02:40, 895.52it/s, epoch=140, loss=[0.3469331206132973, 0.293"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.0999999999999988\n",
      "lr decreased to  1.0999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 360131/480000 [07:08<02:26, 818.09it/s, epoch=150, loss=[0.34681236719091707, 0.29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.9999999999999988\n",
      "lr decreased to  0.9999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 384096/480000 [07:36<01:49, 879.68it/s, epoch=160, loss=[0.34669934198260305, 0.29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.8999999999999988\n",
      "lr decreased to  0.8999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 408087/480000 [08:03<01:22, 874.96it/s, epoch=170, loss=[0.3465924130628506, 0.290"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.7999999999999988\n",
      "lr decreased to  0.7999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 432155/480000 [08:32<00:54, 870.14it/s, epoch=180, loss=[0.34649043055872153, 0.29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.6999999999999988\n",
      "lr decreased to  0.6999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 456153/480000 [09:00<00:29, 815.03it/s, epoch=190, loss=[0.3463950495173535, 0.298"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.5999999999999989\n",
      "lr decreased to  0.5999999999999989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 480000/480000 [09:31<00:00, 840.46it/s, epoch=200, loss=[0.34630627835790295, 0.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1 / 2\n",
      "Complete\n",
      "\n",
      "Initialization 2 / 2\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 24133/480000 [00:30<08:48, 863.06it/s, epoch=10, loss=[0.3586518155038358, 0.24286"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.4\n",
      "lr decreased to  2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 48085/480000 [00:58<08:21, 861.21it/s, epoch=20, loss=[0.3519886412719886, 0.22617"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.3\n",
      "lr decreased to  2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 72094/480000 [01:26<07:21, 924.35it/s, epoch=30, loss=[0.34966737598180747, 0.2163"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.1999999999999997\n",
      "lr decreased to  2.1999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 96138/480000 [01:53<07:55, 807.97it/s, epoch=40, loss=[0.3485680189728736, 0.21021"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.0999999999999996\n",
      "lr decreased to  2.0999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 120144/480000 [02:21<07:40, 781.03it/s, epoch=50, loss=[0.34777996818224577, 0.208"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.9999999999999996\n",
      "lr decreased to  1.9999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 144166/480000 [02:49<06:37, 844.09it/s, epoch=60, loss=[0.3472013551741837, 0.2042"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.8999999999999995\n",
      "lr decreased to  1.8999999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 168105/480000 [03:17<05:48, 894.35it/s, epoch=70, loss=[0.346712753921747, 0.20307"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.7999999999999994\n",
      "lr decreased to  1.7999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 192115/480000 [03:45<05:33, 862.06it/s, epoch=80, loss=[0.3463983477652072, 0.2076"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.6999999999999993\n",
      "lr decreased to  1.6999999999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 216094/480000 [04:13<04:45, 923.69it/s, epoch=90, loss=[0.34614976552625454, 0.203"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.5999999999999992\n",
      "lr decreased to  1.5999999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 240136/480000 [04:40<04:33, 875.85it/s, epoch=100, loss=[0.34594083252052465, 0.20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.4999999999999991\n",
      "lr decreased to  1.4999999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 264149/480000 [05:08<04:04, 882.65it/s, epoch=110, loss=[0.345760867844025, 0.2089"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.399999999999999\n",
      "lr decreased to  1.399999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 288131/480000 [05:35<03:39, 875.76it/s, epoch=120, loss=[0.3456016384065151, 0.199"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.299999999999999\n",
      "lr decreased to  1.299999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 312151/480000 [06:02<03:11, 876.77it/s, epoch=130, loss=[0.3454588057845828, 0.198"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.1999999999999988\n",
      "lr decreased to  1.1999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 336157/480000 [06:30<02:43, 877.58it/s, epoch=140, loss=[0.34532431994875273, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.0999999999999988\n",
      "lr decreased to  1.0999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 360145/480000 [06:57<02:16, 877.16it/s, epoch=150, loss=[0.3452033113439875, 0.196"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.9999999999999988\n",
      "lr decreased to  0.9999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 384176/480000 [07:24<01:48, 879.44it/s, epoch=160, loss=[0.34508730466167187, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.8999999999999988\n",
      "lr decreased to  0.8999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 408144/480000 [07:51<01:20, 898.12it/s, epoch=170, loss=[0.34497964866459313, 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.7999999999999988\n",
      "lr decreased to  0.7999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 432114/480000 [08:19<00:54, 878.82it/s, epoch=180, loss=[0.3447302165627477, 0.195"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.6999999999999988\n",
      "lr decreased to  0.6999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 456141/480000 [08:46<00:27, 873.78it/s, epoch=190, loss=[0.3446313551813361, 0.194"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.5999999999999989\n",
      "lr decreased to  0.5999999999999989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 480000/480000 [09:16<00:00, 863.00it/s, epoch=200, loss=[0.34454193080465023, 0.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1 / 2\n",
      "Complete\n",
      "\n",
      "Initialization 2 / 2\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 24116/480000 [00:29<08:38, 878.75it/s, epoch=10, loss=[0.3601487936079503, 0.30703"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.4\n",
      "lr decreased to  2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 48139/480000 [00:57<08:12, 876.08it/s, epoch=20, loss=[0.3531176572044686, 0.30284"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.3\n",
      "lr decreased to  2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 72165/480000 [01:24<07:50, 866.79it/s, epoch=30, loss=[0.3506968917449309, 0.30569"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.1999999999999997\n",
      "lr decreased to  2.1999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 96107/480000 [01:51<07:16, 878.82it/s, epoch=40, loss=[0.34922413369019806, 0.3003"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.0999999999999996\n",
      "lr decreased to  2.0999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 120124/480000 [02:18<06:48, 880.90it/s, epoch=50, loss=[0.3484926300744214, 0.2995"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.9999999999999996\n",
      "lr decreased to  1.9999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 144103/480000 [02:45<06:23, 876.07it/s, epoch=60, loss=[0.3479938039680323, 0.2987"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.8999999999999995\n",
      "lr decreased to  1.8999999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 168147/480000 [03:13<05:57, 873.22it/s, epoch=70, loss=[0.34762015357613524, 0.298"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.7999999999999994\n",
      "lr decreased to  1.7999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 192109/480000 [03:40<05:29, 872.72it/s, epoch=80, loss=[0.347322388266524, 0.29851"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.6999999999999993\n",
      "lr decreased to  1.6999999999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 216109/480000 [04:07<05:01, 874.25it/s, epoch=90, loss=[0.34707764126360413, 0.299"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.5999999999999992\n",
      "lr decreased to  1.5999999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 240161/480000 [04:35<04:35, 871.32it/s, epoch=100, loss=[0.3466935826092953, 0.299"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.4999999999999991\n",
      "lr decreased to  1.4999999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 264123/480000 [05:02<04:06, 875.56it/s, epoch=110, loss=[0.3465029895802336, 0.297"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.399999999999999\n",
      "lr decreased to  1.399999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 288165/480000 [05:30<03:39, 872.75it/s, epoch=120, loss=[0.34634012425939253, 0.29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.299999999999999\n",
      "lr decreased to  1.299999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 312111/480000 [05:57<03:12, 872.46it/s, epoch=130, loss=[0.3461924427747731, 0.296"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.1999999999999988\n",
      "lr decreased to  1.1999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 336119/480000 [06:25<02:48, 855.93it/s, epoch=140, loss=[0.34605354157586926, 0.29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.0999999999999988\n",
      "lr decreased to  1.0999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 360127/480000 [06:52<02:17, 872.43it/s, epoch=150, loss=[0.3459294751038159, 0.296"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.9999999999999988\n",
      "lr decreased to  0.9999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 384091/480000 [07:19<01:49, 872.37it/s, epoch=160, loss=[0.34581743553280875, 0.29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.8999999999999988\n",
      "lr decreased to  0.8999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 408151/480000 [07:47<01:21, 876.68it/s, epoch=170, loss=[0.3456609039505324, 0.296"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.7999999999999988\n",
      "lr decreased to  0.7999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 432096/480000 [08:14<00:54, 875.03it/s, epoch=180, loss=[0.3455608108143013, 0.296"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.6999999999999988\n",
      "lr decreased to  0.6999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 456131/480000 [08:41<00:28, 843.99it/s, epoch=190, loss=[0.3454687838256357, 0.295"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.5999999999999989\n",
      "lr decreased to  0.5999999999999989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 480000/480000 [09:11<00:00, 870.79it/s, epoch=200, loss=[0.34533030447860574, 0.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1 / 2\n",
      "Complete\n",
      "\n",
      "Initialization 2 / 2\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 24147/480000 [00:29<08:38, 879.90it/s, epoch=10, loss=[0.357384678001205, 0.267694"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.4\n",
      "lr decreased to  2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 48114/480000 [00:57<08:12, 876.53it/s, epoch=20, loss=[0.351270492846767, 0.254521"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.3\n",
      "lr decreased to  2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 72103/480000 [01:24<07:43, 880.11it/s, epoch=30, loss=[0.34889219798147675, 0.2549"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.1999999999999997\n",
      "lr decreased to  2.1999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 96115/480000 [01:51<07:15, 882.34it/s, epoch=40, loss=[0.3477576161424319, 0.25219"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.0999999999999996\n",
      "lr decreased to  2.0999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 120127/480000 [02:18<06:50, 876.18it/s, epoch=50, loss=[0.3468764327218139, 0.2449"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.9999999999999996\n",
      "lr decreased to  1.9999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 144093/480000 [02:46<06:22, 877.50it/s, epoch=60, loss=[0.3463771959642566, 0.2438"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.8999999999999995\n",
      "lr decreased to  1.8999999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 168132/480000 [03:13<05:53, 881.49it/s, epoch=70, loss=[0.3460052681962651, 0.2442"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.7999999999999994\n",
      "lr decreased to  1.7999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 192130/480000 [03:40<05:27, 879.70it/s, epoch=80, loss=[0.3457066559543216, 0.2427"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.6999999999999993\n",
      "lr decreased to  1.6999999999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 216161/480000 [04:08<05:01, 873.81it/s, epoch=90, loss=[0.3454620789239802, 0.2420"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.5999999999999992\n",
      "lr decreased to  1.5999999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 240094/480000 [04:35<04:33, 876.06it/s, epoch=100, loss=[0.3452549100667237, 0.239"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.4999999999999991\n",
      "lr decreased to  1.4999999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 264167/480000 [05:02<03:58, 906.32it/s, epoch=110, loss=[0.34507507349054023, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.399999999999999\n",
      "lr decreased to  1.399999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 288173/480000 [05:30<03:32, 902.16it/s, epoch=120, loss=[0.3449161860346793, 0.237"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.299999999999999\n",
      "lr decreased to  1.299999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 312105/480000 [05:57<03:11, 876.21it/s, epoch=130, loss=[0.34477317355573156, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.1999999999999988\n",
      "lr decreased to  1.1999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 336145/480000 [06:24<02:39, 904.14it/s, epoch=140, loss=[0.34464319926996984, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.0999999999999988\n",
      "lr decreased to  1.0999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 360117/480000 [06:51<02:16, 879.63it/s, epoch=150, loss=[0.34452190573016767, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.9999999999999988\n",
      "lr decreased to  0.9999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 384110/480000 [07:18<01:48, 882.73it/s, epoch=160, loss=[0.3444090247154234, 0.235"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.8999999999999988\n",
      "lr decreased to  0.8999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 408140/480000 [07:45<01:21, 877.08it/s, epoch=170, loss=[0.34430369849006365, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.7999999999999988\n",
      "lr decreased to  0.7999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 432155/480000 [08:13<00:54, 876.56it/s, epoch=180, loss=[0.34420494894186593, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.6999999999999988\n",
      "lr decreased to  0.6999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 456093/480000 [08:40<00:27, 883.02it/s, epoch=190, loss=[0.34411005529264627, 0.23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.5999999999999989\n",
      "lr decreased to  0.5999999999999989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 480000/480000 [09:09<00:00, 872.93it/s, epoch=200, loss=[0.34402099631726746, 0.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1 / 2\n",
      "Complete\n",
      "\n",
      "Initialization 2 / 2\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 24103/480000 [00:29<08:38, 879.10it/s, epoch=10, loss=[0.35702761933207555, 0.2696"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.4\n",
      "lr decreased to  2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 48153/480000 [00:57<08:16, 869.86it/s, epoch=20, loss=[0.35094152706364834, 0.2578"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.3\n",
      "lr decreased to  2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 72143/480000 [01:24<07:45, 876.87it/s, epoch=30, loss=[0.34873412022988015, 0.2499"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.1999999999999997\n",
      "lr decreased to  2.1999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 96109/480000 [01:51<07:17, 877.22it/s, epoch=40, loss=[0.34735359959304324, 0.2445"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  2.0999999999999996\n",
      "lr decreased to  2.0999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 120146/480000 [02:19<06:51, 874.78it/s, epoch=50, loss=[0.3466178977737829, 0.2375"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.9999999999999996\n",
      "lr decreased to  1.9999999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 144161/480000 [02:46<06:24, 874.05it/s, epoch=60, loss=[0.3461138614267112, 0.2438"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.8999999999999995\n",
      "lr decreased to  1.8999999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 168165/480000 [03:13<05:57, 872.91it/s, epoch=70, loss=[0.3457282591114439, 0.2333"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.7999999999999994\n",
      "lr decreased to  1.7999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 192168/480000 [03:40<05:31, 868.36it/s, epoch=80, loss=[0.34542061090469356, 0.231"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.6999999999999993\n",
      "lr decreased to  1.6999999999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 216147/480000 [04:07<04:59, 880.70it/s, epoch=90, loss=[0.3451669081300501, 0.2332"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.5999999999999992\n",
      "lr decreased to  1.5999999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 240114/480000 [04:35<04:34, 875.33it/s, epoch=100, loss=[0.344954571425915, 0.2324"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.4999999999999991\n",
      "lr decreased to  1.4999999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 264158/480000 [05:02<04:04, 881.23it/s, epoch=110, loss=[0.34476777717471124, 0.22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.399999999999999\n",
      "lr decreased to  1.399999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 288141/480000 [05:29<03:39, 875.15it/s, epoch=120, loss=[0.344602781583866, 0.2284"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.299999999999999\n",
      "lr decreased to  1.299999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 312118/480000 [05:57<03:15, 860.03it/s, epoch=130, loss=[0.34440896034240737, 0.22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.1999999999999988\n",
      "lr decreased to  1.1999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 336103/480000 [06:24<02:46, 862.83it/s, epoch=140, loss=[0.3442651216934127, 0.227"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  1.0999999999999988\n",
      "lr decreased to  1.0999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 360121/480000 [06:52<02:16, 875.72it/s, epoch=150, loss=[0.34414122139414133, 0.22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.9999999999999988\n",
      "lr decreased to  0.9999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 384157/480000 [07:19<01:49, 878.10it/s, epoch=160, loss=[0.34402695313096143, 0.22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.8999999999999988\n",
      "lr decreased to  0.8999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 408113/480000 [07:46<01:22, 875.49it/s, epoch=170, loss=[0.3439207591364783, 0.226"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.7999999999999988\n",
      "lr decreased to  0.7999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 432128/480000 [08:14<00:53, 899.45it/s, epoch=180, loss=[0.34382112453381164, 0.22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.6999999999999988\n",
      "lr decreased to  0.6999999999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 456105/480000 [08:41<00:27, 875.29it/s, epoch=190, loss=[0.34372727103531375, 0.22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr decreased to  0.5999999999999989\n",
      "lr decreased to  0.5999999999999989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 480000/480000 [09:10<00:00, 871.63it/s, epoch=200, loss=[0.3436376667519412, 0.223\n"
     ]
    }
   ],
   "source": [
    "# ratio = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "ratio = [0.2]\n",
    "test_acc = []\n",
    "train_acc = []\n",
    "w_layers = []\n",
    "loss = []\n",
    "\n",
    "num_runs = 5\n",
    "\n",
    "# for r in ratio:\n",
    "    # print(f\"train ratio: {r}\")\n",
    "'''    \n",
    "test_size = int(r * len(full_data_set))\n",
    "train_size = len(full_data_set) - test_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_data_set, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for training set\n",
    "trainloader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "\n",
    "# Create DataLoader for test set\n",
    "testloader = DataLoader(test_dataset, batch_size = 64, shuffle=False)\n",
    "'''\n",
    "for _ in range(num_runs):\n",
    "    \n",
    "    dims_list = [784, 1024, 10]\n",
    "    # dims_list = [784, 1000, 34]\n",
    "    bias = True\n",
    "    epochs = 200\n",
    "    lr  = 2.5\n",
    "    num_classes = 10\n",
    "    net = Net(dims_list, bias, epochs, lr, device)\n",
    "    \n",
    "    # Train the network\n",
    "    layer_loss_list = net.train(trainloader, testloader)\n",
    "    \n",
    "    # plot_losses(layer_loss_list[0])\n",
    "    \n",
    "    '''\n",
    "    # Test the network\n",
    "    acc_train = net.test(trainloader)\n",
    "    print(f\"Train accuracy: {acc_train * 100:.2f}%\")\n",
    "    \n",
    "    acc_test = net.test(testloader)\n",
    "    print(f\"Test accuracy: {acc_test * 100:.2f}%\")\n",
    "    '''\n",
    "    loss.append(layer_loss_list[0])\n",
    "    train_acc.append(layer_loss_list[1])\n",
    "    test_acc.append(layer_loss_list[2])\n",
    "    w_layers.append(layer_loss_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[array([0.091 , 0.1028])], [array([0.9091, 0.9473])]], [[array([0.0573, 0.0874])], [array([0.9127, 0.9424])]], [[array([0.1076, 0.0793])], [array([0.9102, 0.9513])]], [[array([0.105 , 0.1056])], [array([0.9113, 0.9367])]], [[array([0.1005, 0.0762])], [array([0.9111, 0.943 ])]]]\n",
      "0.9513\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)\n",
    "print(np.max(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[array([0.09076667, 0.0997    ])], [array([0.91275   , 0.96038333])]], [[array([0.05856667, 0.08715   ])], [array([0.91411667, 0.95235   ])]], [[array([0.10648333, 0.0795    ])], [array([0.9134, 0.9642])]], [[array([0.10083333, 0.10225   ])], [array([0.91388333, 0.9476    ])]], [[array([0.10016667, 0.08095   ])], [array([0.91416667, 0.95056667])]]]\n",
      "0.9642\n"
     ]
    }
   ],
   "source": [
    "print(train_acc)\n",
    "print(np.max(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./../new_data/ablation_pure_mnist_train_acc.npy\", np.array(train_acc))\n",
    "np.save(\"./../new_data/ablation_pure_mnist_test_acc.npy\", np.array(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
